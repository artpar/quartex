# AI-First macOS Application - Claude Context

## Project Overview

This is an AI-first macOS application built in Swift that transforms user inputs (text, audio, video) into actions through LLM-powered decision making. The application serves as a universal interface where every functionality is delegated to an AI agent that can utilize various tools and plugins.

## Current State

**Existing Files:**
- `main.swift` - App entry point with NSApplicationMain
- `AppDelegate.swift` - Window creation and app lifecycle management  
- Complete Core infrastructure with AIAgent, LLMClient, Models, Utils
- Comprehensive test suite with 72 tests (0 failures)
- `Makefile` - Enhanced build system with testing targets
- `Info.plist` - App metadata
- `config.json` - Configuration with Anthropic API integration

**Current Functionality:**
- Fully functional chat interface with real-time streaming text
- Working Anthropic Claude API integration with proper authentication
- Complete tool system with file operations (read/write/create/list)
- Multi-turn conversation support with context retention
- Character-by-character streaming UI with visual cursor
- Comprehensive error handling and logging
- Extensive test coverage (Unit, Integration, Performance, Security, UI)

## Architecture Overview

### Core Design Principles
1. **Agent-Centric**: Single AIAgent orchestrates all interactions
2. **LLM-Driven**: Every functionality decision made through /completions API
3. **Multi-Modal**: Support for text, audio, video, and file inputs
4. **Tool-Based**: Extensible system of tools/functions the AI can invoke
5. **Plugin Architecture**: Third-party extensibility through plugins

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UI Layer      â”‚â—„â”€â”€â–ºâ”‚   AI Agent      â”‚â—„â”€â”€â–ºâ”‚  Tool System    â”‚
â”‚                 â”‚    â”‚     Core        â”‚    â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Chat Interfaceâ”‚    â”‚ â€¢ LLM Client    â”‚    â”‚ â€¢ System Tools  â”‚
â”‚ â€¢ Input Capture â”‚    â”‚ â€¢ Context Mgmt  â”‚    â”‚ â€¢ File Tools    â”‚
â”‚ â€¢ Media Display â”‚    â”‚ â€¢ Conversation  â”‚    â”‚ â€¢ Web Tools     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Input Layer    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                 â”‚
                        â”‚ â€¢ Text Processorâ”‚
                        â”‚ â€¢ Audio Handler â”‚
                        â”‚ â€¢ Video Analyzerâ”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure Plan

```
/
â”œâ”€â”€ Core/
â”‚   â”œâ”€â”€ AIAgent/
â”‚   â”‚   â”œâ”€â”€ AIAgent.swift              # Central orchestrator
â”‚   â”‚   â”œâ”€â”€ LLMClient.swift            # /completions API client
â”‚   â”‚   â”œâ”€â”€ ConversationManager.swift  # Chat history & context
â”‚   â”‚   â”œâ”€â”€ ContextManager.swift       # System context tracking
â”‚   â”‚   â””â”€â”€ StreamingHandler.swift     # Real-time response streaming
â”‚   â”‚
â”‚   â”œâ”€â”€ InputProcessing/
â”‚   â”‚   â”œâ”€â”€ InputCoordinator.swift     # Multi-modal input router
â”‚   â”‚   â”œâ”€â”€ TextProcessor.swift        # Text analysis & preprocessing
â”‚   â”‚   â”œâ”€â”€ AudioProcessor.swift       # Speech-to-text conversion
â”‚   â”‚   â”œâ”€â”€ VideoProcessor.swift       # Video frame analysis
â”‚   â”‚   â””â”€â”€ FileProcessor.swift        # Document/image processing
â”‚   â”‚
â”‚   â”œâ”€â”€ ToolSystem/
â”‚   â”‚   â”œâ”€â”€ ToolRegistry.swift         # Available tools catalog
â”‚   â”‚   â”œâ”€â”€ ToolExecutor.swift         # Tool invocation engine
â”‚   â”‚   â”œâ”€â”€ FunctionCalling.swift      # LLM function call parsing
â”‚   â”‚   â””â”€â”€ Tools/
â”‚   â”‚       â”œâ”€â”€ SystemTools.swift      # OS integration
â”‚   â”‚       â”œâ”€â”€ FileTools.swift        # File operations
â”‚   â”‚       â”œâ”€â”€ WebTools.swift         # Web browsing/requests
â”‚   â”‚       â”œâ”€â”€ AppTools.swift         # App control/automation
â”‚   â”‚       â””â”€â”€ MediaTools.swift       # Audio/video manipulation
â”‚   â”‚
â”‚   â””â”€â”€ Extensions/
â”‚       â”œâ”€â”€ PluginManager.swift        # Plugin lifecycle management
â”‚       â”œâ”€â”€ PluginProtocol.swift       # Plugin interface definition
â”‚       â””â”€â”€ SecurityManager.swift      # Sandboxing & permissions
â”‚
â”œâ”€â”€ UI/
â”‚   â”œâ”€â”€ Components/
â”‚   â”‚   â”œâ”€â”€ ChatViewController.swift   # Main chat interface
â”‚   â”‚   â”œâ”€â”€ InputArea.swift           # Multi-modal input component
â”‚   â”‚   â”œâ”€â”€ MessageBubble.swift       # Chat message display
â”‚   â”‚   â”œâ”€â”€ MediaViewer.swift         # Image/video display
â”‚   â”‚   â”œâ”€â”€ ToolOutputView.swift      # Tool execution results
â”‚   â”‚   â””â”€â”€ StreamingTextView.swift   # Real-time text streaming
â”‚   â”‚
â”‚   â”œâ”€â”€ Windows/
â”‚   â”‚   â”œâ”€â”€ MainWindow.swift          # Primary app window
â”‚   â”‚   â”œâ”€â”€ SettingsWindow.swift      # Configuration panel
â”‚   â”‚   â””â”€â”€ DebugWindow.swift         # Development tools
â”‚   â”‚
â”‚   â””â”€â”€ ViewModels/
â”‚       â”œâ”€â”€ ChatViewModel.swift       # Chat state management
â”‚       â”œâ”€â”€ InputViewModel.swift      # Input handling logic
â”‚       â””â”€â”€ SettingsViewModel.swift   # Settings state
â”‚
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ AudioService.swift            # Audio capture/playback
â”‚   â”œâ”€â”€ VideoService.swift            # Camera/screen capture
â”‚   â”œâ”€â”€ FileService.swift             # File system operations
â”‚   â”œâ”€â”€ NetworkService.swift          # HTTP/WebSocket client
â”‚   â”œâ”€â”€ SecurityService.swift         # Permission management
â”‚   â””â”€â”€ NotificationService.swift     # User notifications
â”‚
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ Message.swift                 # Chat message model
â”‚   â”œâ”€â”€ Conversation.swift            # Conversation model
â”‚   â”œâ”€â”€ Tool.swift                    # Tool definition model
â”‚   â”œâ”€â”€ Plugin.swift                  # Plugin model
â”‚   â”œâ”€â”€ InputEvent.swift              # Multi-modal input event
â”‚   â””â”€â”€ AIResponse.swift              # LLM response model
â”‚
â”œâ”€â”€ Utils/
â”‚   â”œâ”€â”€ Logger.swift                  # Logging system
â”‚   â”œâ”€â”€ Configuration.swift           # App settings
â”‚   â”œâ”€â”€ Extensions.swift              # Swift extensions
â”‚   â”œâ”€â”€ Constants.swift               # App constants
â”‚   â””â”€â”€ ErrorHandling.swift           # Error management
â”‚
â””â”€â”€ Resources/
    â”œâ”€â”€ Prompts/                      # System prompts
    â”œâ”€â”€ Plugins/                      # Bundled plugins
    â””â”€â”€ Assets/                       # UI assets
```

## Key Components

### AIAgent (Core/AIAgent/AIAgent.swift)
- Central orchestrator for all AI interactions
- Manages conversation flow and context
- Decides which tools to invoke based on user input
- Handles streaming responses from LLM

### LLM Integration
- Uses /completions compatible endpoints
- Supports function calling for tool invocation
- Streaming response handling for real-time updates
- Context window management for long conversations

### Tool System
- Registry of available tools/functions
- Standardized tool interface for easy extension
- Security sandboxing for tool execution
- Built-in tools: file operations, system commands, web browsing, media processing

### Multi-Modal Input Processing
- Text: Direct input processing
- Audio: Speech-to-text using macOS Speech framework
- Video: Frame analysis and content extraction
- Files: Document parsing, image analysis

### Plugin Architecture
```swift
protocol AIPlugin {
    var name: String { get }
    var tools: [Tool] { get }
    func execute(tool: Tool, parameters: [String: Any]) async -> ToolResult
}
```

## Implementation Phases

### Phase 1: Core Infrastructure âœ… COMPLETED
- âœ… Replace current UI with basic chat interface
- âœ… Implement LLM client with /completions API
- âœ… Create basic tool system (file operations, system commands)
- âœ… Set up conversation management
- âœ… Comprehensive test suite with 72 tests passing
- âœ… Real-time streaming UI with character-by-character display

### Phase 2: Multi-Modal Input ðŸš§ IN PROGRESS
- ðŸ”„ Add audio input with Speech framework
- ðŸ”„ Implement file upload and processing
- ðŸ”„ Add camera/screen capture integration
- ðŸ”„ Create unified input processing pipeline

### Phase 3: Advanced Features
- Implement plugin system
- Add advanced context management
- Create tool chaining and workflow automation
- Implement streaming UI updates

### Phase 4: Polish & Optimization
- Performance optimization and caching
- Security hardening and sandboxing
- Advanced UI features and customization
- Comprehensive testing and error handling

## Development Guidelines

### Code Style
- Follow Swift naming conventions
- Use async/await for asynchronous operations
- Implement proper error handling with Result types
- Use dependency injection for testability

### Security Considerations
- Sandbox tool execution
- Validate all LLM function calls
- Implement permission system for sensitive operations
- Secure API key storage in Keychain

### Testing Strategy
- Unit tests for core logic components
- Integration tests for LLM interactions
- UI tests for main user workflows
- Performance tests for streaming and tool execution

## Configuration

### Environment Variables
- `ANTHROPIC_API_KEY` or equivalent for LLM API access
- `LLM_ENDPOINT` for custom /completions endpoints
- `DEBUG_MODE` for development features

### Build Commands
- `make` - Build the application
- `make run` - Build and run the application
- `make clean` - Clean build artifacts
- `make install` - Install to /Applications

## Notes for Future Development

1. **Maintain backwards compatibility** when extending the tool system
2. **Plugin security** is critical - implement proper sandboxing
3. **Context management** will be key for long conversations
4. **Performance optimization** needed for real-time streaming
5. **User experience** should prioritize responsiveness and clarity

This architecture ensures maintainability through clear separation of concerns, extensibility via the plugin system, and scalability through modular design.

## TODO Management

This project uses a TODO.md file to track development progress and maintain a working plan. Every Claude CLI session should:

1. **Read TODO.md** at the start to understand current priorities and context
2. **Update TODO.md** as tasks are completed, modified, or new requirements emerge
3. **Maintain CLAUDE.md** with any architectural changes or new insights
4. **Keep project state synchronized** between documentation and actual codebase

### TODO.md Structure
- **Current Phase**: Which implementation phase we're in
- **Active Tasks**: Current development priorities with status
- **Completed Tasks**: Recently finished work for context
- **Next Steps**: Upcoming priorities based on current progress
- **Blockers**: Any issues preventing progress
- **Notes**: Important context or decisions made

### Development Workflow
1. Start each session by reading CLAUDE.md and TODO.md
2. Update TODO.md status before beginning work
3. Document any architectural decisions in CLAUDE.md
4. Update TODO.md with progress before ending session
5. Ensure all changes maintain project consistency